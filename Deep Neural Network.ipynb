{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converage type detection using Softmax\n",
    "\n",
    "The dataset was obtained from [UCI Machine learning repository](https://archive.ics.uci.edu/ml/datasets/Covertype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2596</th>\n",
       "      <th>51</th>\n",
       "      <th>3</th>\n",
       "      <th>258</th>\n",
       "      <th>0</th>\n",
       "      <th>510</th>\n",
       "      <th>221</th>\n",
       "      <th>232</th>\n",
       "      <th>148</th>\n",
       "      <th>6279</th>\n",
       "      <th>...</th>\n",
       "      <th>0.34</th>\n",
       "      <th>0.35</th>\n",
       "      <th>0.36</th>\n",
       "      <th>0.37</th>\n",
       "      <th>0.38</th>\n",
       "      <th>0.39</th>\n",
       "      <th>0.40</th>\n",
       "      <th>0.41</th>\n",
       "      <th>0.42</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>6225</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>6121</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>6211</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2595</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>6172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2579</td>\n",
       "      <td>132</td>\n",
       "      <td>6</td>\n",
       "      <td>300</td>\n",
       "      <td>-15</td>\n",
       "      <td>67</td>\n",
       "      <td>230</td>\n",
       "      <td>237</td>\n",
       "      <td>140</td>\n",
       "      <td>6031</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   2596   51   3  258    0   510  221  232  148  6279 ...  0.34  0.35  0.36  \\\n",
       "0  2590   56   2  212   -6   390  220  235  151  6225 ...     0     0     0   \n",
       "1  2804  139   9  268   65  3180  234  238  135  6121 ...     0     0     0   \n",
       "2  2785  155  18  242  118  3090  238  238  122  6211 ...     0     0     0   \n",
       "3  2595   45   2  153   -1   391  220  234  150  6172 ...     0     0     0   \n",
       "4  2579  132   6  300  -15    67  230  237  140  6031 ...     0     0     0   \n",
       "\n",
       "   0.37  0.38  0.39  0.40  0.41  0.42  5  \n",
       "0     0     0     0     0     0     0  5  \n",
       "1     0     0     0     0     0     0  2  \n",
       "2     0     0     0     0     0     0  2  \n",
       "3     0     0     0     0     0     0  5  \n",
       "4     0     0     0     0     0     0  2  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data into a DataFrame    \n",
    "data = pd.read_csv('~/Downloads/covtype.data')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2596</th>\n",
       "      <th>51</th>\n",
       "      <th>3</th>\n",
       "      <th>258</th>\n",
       "      <th>0</th>\n",
       "      <th>510</th>\n",
       "      <th>221</th>\n",
       "      <th>232</th>\n",
       "      <th>148</th>\n",
       "      <th>6279</th>\n",
       "      <th>...</th>\n",
       "      <th>0.34</th>\n",
       "      <th>0.35</th>\n",
       "      <th>0.36</th>\n",
       "      <th>0.37</th>\n",
       "      <th>0.38</th>\n",
       "      <th>0.39</th>\n",
       "      <th>0.40</th>\n",
       "      <th>0.41</th>\n",
       "      <th>0.42</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>581011.000000</td>\n",
       "      <td>581011.000000</td>\n",
       "      <td>581011.000000</td>\n",
       "      <td>581011.000000</td>\n",
       "      <td>581011.000000</td>\n",
       "      <td>581011.000000</td>\n",
       "      <td>581011.000000</td>\n",
       "      <td>581011.000000</td>\n",
       "      <td>581011.000000</td>\n",
       "      <td>581011.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>581011.000000</td>\n",
       "      <td>581011.000000</td>\n",
       "      <td>581011.000000</td>\n",
       "      <td>581011.000000</td>\n",
       "      <td>581011.000000</td>\n",
       "      <td>581011.000000</td>\n",
       "      <td>581011.000000</td>\n",
       "      <td>581011.000000</td>\n",
       "      <td>581011.000000</td>\n",
       "      <td>581011.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2959.365926</td>\n",
       "      <td>155.656988</td>\n",
       "      <td>14.103723</td>\n",
       "      <td>269.428236</td>\n",
       "      <td>46.418935</td>\n",
       "      <td>2350.149779</td>\n",
       "      <td>212.146033</td>\n",
       "      <td>223.318701</td>\n",
       "      <td>142.528253</td>\n",
       "      <td>1980.283828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090392</td>\n",
       "      <td>0.077716</td>\n",
       "      <td>0.002773</td>\n",
       "      <td>0.003255</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.026803</td>\n",
       "      <td>0.023762</td>\n",
       "      <td>0.015060</td>\n",
       "      <td>2.051465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>279.984569</td>\n",
       "      <td>111.913733</td>\n",
       "      <td>7.488234</td>\n",
       "      <td>212.549538</td>\n",
       "      <td>58.295250</td>\n",
       "      <td>1559.254343</td>\n",
       "      <td>26.769909</td>\n",
       "      <td>19.768711</td>\n",
       "      <td>38.274561</td>\n",
       "      <td>1324.184340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.286743</td>\n",
       "      <td>0.267725</td>\n",
       "      <td>0.052584</td>\n",
       "      <td>0.056957</td>\n",
       "      <td>0.014310</td>\n",
       "      <td>0.022641</td>\n",
       "      <td>0.161508</td>\n",
       "      <td>0.152307</td>\n",
       "      <td>0.121792</td>\n",
       "      <td>1.396500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1859.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-173.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2809.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1106.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>1024.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2996.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1997.000000</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>1710.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3163.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>3328.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>237.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>2550.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3858.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>601.000000</td>\n",
       "      <td>7117.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>7173.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                2596             51              3            258  \\\n",
       "count  581011.000000  581011.000000  581011.000000  581011.000000   \n",
       "mean     2959.365926     155.656988      14.103723     269.428236   \n",
       "std       279.984569     111.913733       7.488234     212.549538   \n",
       "min      1859.000000       0.000000       0.000000       0.000000   \n",
       "25%      2809.000000      58.000000       9.000000     108.000000   \n",
       "50%      2996.000000     127.000000      13.000000     218.000000   \n",
       "75%      3163.000000     260.000000      18.000000     384.000000   \n",
       "max      3858.000000     360.000000      66.000000    1397.000000   \n",
       "\n",
       "                   0            510            221            232  \\\n",
       "count  581011.000000  581011.000000  581011.000000  581011.000000   \n",
       "mean       46.418935    2350.149779     212.146033     223.318701   \n",
       "std        58.295250    1559.254343      26.769909      19.768711   \n",
       "min      -173.000000       0.000000       0.000000       0.000000   \n",
       "25%         7.000000    1106.000000     198.000000     213.000000   \n",
       "50%        30.000000    1997.000000     218.000000     226.000000   \n",
       "75%        69.000000    3328.000000     231.000000     237.000000   \n",
       "max       601.000000    7117.000000     254.000000     254.000000   \n",
       "\n",
       "                 148           6279      ...                 0.34  \\\n",
       "count  581011.000000  581011.000000      ...        581011.000000   \n",
       "mean      142.528253    1980.283828      ...             0.090392   \n",
       "std        38.274561    1324.184340      ...             0.286743   \n",
       "min         0.000000       0.000000      ...             0.000000   \n",
       "25%       119.000000    1024.000000      ...             0.000000   \n",
       "50%       143.000000    1710.000000      ...             0.000000   \n",
       "75%       168.000000    2550.000000      ...             0.000000   \n",
       "max       254.000000    7173.000000      ...             1.000000   \n",
       "\n",
       "                0.35           0.36           0.37           0.38  \\\n",
       "count  581011.000000  581011.000000  581011.000000  581011.000000   \n",
       "mean        0.077716       0.002773       0.003255       0.000205   \n",
       "std         0.267725       0.052584       0.056957       0.014310   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "                0.39           0.40           0.41           0.42  \\\n",
       "count  581011.000000  581011.000000  581011.000000  581011.000000   \n",
       "mean        0.000513       0.026803       0.023762       0.015060   \n",
       "std         0.022641       0.161508       0.152307       0.121792   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "                   5  \n",
       "count  581011.000000  \n",
       "mean        2.051465  \n",
       "std         1.396500  \n",
       "min         1.000000  \n",
       "25%         1.000000  \n",
       "50%         2.000000  \n",
       "75%         2.000000  \n",
       "max         7.000000  \n",
       "\n",
       "[8 rows x 55 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(df):\n",
    "    columns = df.shape[1]\n",
    "    \n",
    "    X1 = df[df.columns[0:10]]\n",
    "    X1 = (X1 - X1.mean())/X1.std()\n",
    "    X2 = df[df.columns[10:]]\n",
    "    \n",
    "    X = pd.concat([X1, X2], axis=1)    \n",
    "    Y = pd.get_dummies(df[df.columns[columns - 1]])\n",
    "    return X.values, Y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(data, test_size=0.2, random_state=100)\n",
    "train_X, train_Y = create_dataset(train_set)\n",
    "test_X, test_Y = create_dataset(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_batch(X, Y, idx, batch_size):\n",
    "    return X[idx*batch_size: (idx + 1)*batch_size], Y[idx*batch_size: (idx + 1)*batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_model(train_X, train_Y, test_X, test_Y, layers = [], \n",
    "                         epochs=10, regularization=0.1, batch_size=10):\n",
    "    weights = None\n",
    "    bias = None\n",
    "    \n",
    "    assert(len(layers) > 1)\n",
    "    assert(layers[0] == train_X.shape[1])\n",
    "    L = layers\n",
    "    feature_cnt = train_X.shape[1]\n",
    "    class_cnt = test_Y.shape[1]\n",
    "    # Mini Batch Gradient descent parameters\n",
    "    batch_cnt = int(train_X.shape[0]/batch_size)\n",
    "       \n",
    "    X = tf.placeholder(tf.float32, shape=(None, feature_cnt))\n",
    "    Y = tf.placeholder(tf.float32, shape=(None, class_cnt))\n",
    "\n",
    "    w1 = tf.Variable(0.01*tf.random_normal(shape=(feature_cnt, L[1])))\n",
    "    b1 = tf.Variable(tf.zeros(L[1], 1))\n",
    "    Y1 = tf.nn.relu(tf.matmul(X, w1) + b1)\n",
    "    \n",
    "    w2 = tf.Variable(0.01*tf.random_normal(shape=(L[1], L[2])))\n",
    "    b2 = tf.Variable(tf.zeros(L[2], 1))\n",
    "    Y2 = tf.nn.relu(tf.matmul(Y1, w2) + b2)\n",
    "\n",
    "    w = tf.Variable(0.01*tf.random_normal(shape=(L[2], L[3])))\n",
    "    b = tf.Variable(tf.zeros(L[3], 1))    \n",
    "    Y_predicted = tf.nn.softmax(tf.matmul(Y2, w) + b) \n",
    "    \n",
    "    loss = -1000.0*tf.reduce_mean(Y*tf.log(Y_predicted))\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.005).minimize(loss)\n",
    "    \n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "  \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            for idx in range(0, batch_cnt):\n",
    "                mini_X, mini_Y = get_next_batch(train_X, train_Y, idx, batch_size)\n",
    "            \n",
    "                train_loss_val,_ = sess.run([loss, optimizer], feed_dict={X: mini_X, Y: mini_Y})\n",
    "                train_losses.append(train_loss_val)\n",
    "                \n",
    "                test_loss_val = sess.run([loss], feed_dict={X: test_X, Y: test_Y})\n",
    "                test_losses.append(test_loss_val)\n",
    "    \n",
    "                \n",
    "        plt.plot(range(0, epochs*batch_cnt), train_losses, '-',label='training')\n",
    "        plt.plot(range(0, epochs*batch_cnt), test_losses, '-', label='test')\n",
    "        plt.xlabel('Iterations')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()  \n",
    "       \n",
    "        # Test the regression model\n",
    "        correct_predictions = tf.equal(tf.argmax(Y_predicted, 1), tf.argmax(test_Y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
    "        return sess.run(accuracy, feed_dict={X: test_X, Y: test_Y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(464808, 55)\n",
      "[55, 110, 27, 7]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMT2ygDDGGNMjCwhjjDE9soAwxhjTo/8PaC/fYKl+1wYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0bf79dfac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.949648\n"
     ]
    }
   ],
   "source": [
    "feature_cnt = train_X.shape[1]\n",
    "print(train_X.shape)\n",
    "layers = list(map(int, [feature_cnt, 2*feature_cnt, feature_cnt/2, train_Y.shape[1]]))\n",
    "print(layers)\n",
    "accuracy = classification_model(train_X, train_Y, test_X, test_Y, layers=layers, batch_size=10000)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
