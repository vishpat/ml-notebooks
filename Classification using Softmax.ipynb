{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converage type detection using Softmax\n",
    "\n",
    "The dataset was obtained from [UCI Machine learning repository](https://archive.ics.uci.edu/ml/datasets/Covertype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2596</th>\n",
       "      <th>51</th>\n",
       "      <th>3</th>\n",
       "      <th>258</th>\n",
       "      <th>0</th>\n",
       "      <th>510</th>\n",
       "      <th>221</th>\n",
       "      <th>232</th>\n",
       "      <th>148</th>\n",
       "      <th>6279</th>\n",
       "      <th>...</th>\n",
       "      <th>0.34</th>\n",
       "      <th>0.35</th>\n",
       "      <th>0.36</th>\n",
       "      <th>0.37</th>\n",
       "      <th>0.38</th>\n",
       "      <th>0.39</th>\n",
       "      <th>0.40</th>\n",
       "      <th>0.41</th>\n",
       "      <th>0.42</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>6225</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>6121</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>6211</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2595</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>6172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2579</td>\n",
       "      <td>132</td>\n",
       "      <td>6</td>\n",
       "      <td>300</td>\n",
       "      <td>-15</td>\n",
       "      <td>67</td>\n",
       "      <td>230</td>\n",
       "      <td>237</td>\n",
       "      <td>140</td>\n",
       "      <td>6031</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   2596   51   3  258    0   510  221  232  148  6279 ...  0.34  0.35  0.36  \\\n",
       "0  2590   56   2  212   -6   390  220  235  151  6225 ...     0     0     0   \n",
       "1  2804  139   9  268   65  3180  234  238  135  6121 ...     0     0     0   \n",
       "2  2785  155  18  242  118  3090  238  238  122  6211 ...     0     0     0   \n",
       "3  2595   45   2  153   -1   391  220  234  150  6172 ...     0     0     0   \n",
       "4  2579  132   6  300  -15    67  230  237  140  6031 ...     0     0     0   \n",
       "\n",
       "   0.37  0.38  0.39  0.40  0.41  0.42  5  \n",
       "0     0     0     0     0     0     0  5  \n",
       "1     0     0     0     0     0     0  2  \n",
       "2     0     0     0     0     0     0  2  \n",
       "3     0     0     0     0     0     0  5  \n",
       "4     0     0     0     0     0     0  2  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data into a DataFrame    \n",
    "data = pd.read_csv('~/Downloads/covtype.data')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2596</th>\n",
       "      <th>51</th>\n",
       "      <th>3</th>\n",
       "      <th>258</th>\n",
       "      <th>0</th>\n",
       "      <th>510</th>\n",
       "      <th>221</th>\n",
       "      <th>232</th>\n",
       "      <th>148</th>\n",
       "      <th>6279</th>\n",
       "      <th>...</th>\n",
       "      <th>0.34</th>\n",
       "      <th>0.35</th>\n",
       "      <th>0.36</th>\n",
       "      <th>0.37</th>\n",
       "      <th>0.38</th>\n",
       "      <th>0.39</th>\n",
       "      <th>0.40</th>\n",
       "      <th>0.41</th>\n",
       "      <th>0.42</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>581011.000000</td>\n",
       "      <td>581011.000000</td>\n",
       "      <td>581011.000000</td>\n",
       "      <td>581011.000000</td>\n",
       "      <td>581011.000000</td>\n",
       "      <td>581011.000000</td>\n",
       "      <td>581011.000000</td>\n",
       "      <td>581011.000000</td>\n",
       "      <td>581011.000000</td>\n",
       "      <td>581011.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>581011.000000</td>\n",
       "      <td>581011.000000</td>\n",
       "      <td>581011.000000</td>\n",
       "      <td>581011.000000</td>\n",
       "      <td>581011.000000</td>\n",
       "      <td>581011.000000</td>\n",
       "      <td>581011.000000</td>\n",
       "      <td>581011.000000</td>\n",
       "      <td>581011.000000</td>\n",
       "      <td>581011.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2959.365926</td>\n",
       "      <td>155.656988</td>\n",
       "      <td>14.103723</td>\n",
       "      <td>269.428236</td>\n",
       "      <td>46.418935</td>\n",
       "      <td>2350.149779</td>\n",
       "      <td>212.146033</td>\n",
       "      <td>223.318701</td>\n",
       "      <td>142.528253</td>\n",
       "      <td>1980.283828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090392</td>\n",
       "      <td>0.077716</td>\n",
       "      <td>0.002773</td>\n",
       "      <td>0.003255</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.026803</td>\n",
       "      <td>0.023762</td>\n",
       "      <td>0.015060</td>\n",
       "      <td>2.051465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>279.984569</td>\n",
       "      <td>111.913733</td>\n",
       "      <td>7.488234</td>\n",
       "      <td>212.549538</td>\n",
       "      <td>58.295250</td>\n",
       "      <td>1559.254343</td>\n",
       "      <td>26.769909</td>\n",
       "      <td>19.768711</td>\n",
       "      <td>38.274561</td>\n",
       "      <td>1324.184340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.286743</td>\n",
       "      <td>0.267725</td>\n",
       "      <td>0.052584</td>\n",
       "      <td>0.056957</td>\n",
       "      <td>0.014310</td>\n",
       "      <td>0.022641</td>\n",
       "      <td>0.161508</td>\n",
       "      <td>0.152307</td>\n",
       "      <td>0.121792</td>\n",
       "      <td>1.396500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1859.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-173.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2809.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1106.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>1024.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2996.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1997.000000</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>1710.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3163.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>3328.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>237.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>2550.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3858.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>601.000000</td>\n",
       "      <td>7117.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>7173.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                2596             51              3            258  \\\n",
       "count  581011.000000  581011.000000  581011.000000  581011.000000   \n",
       "mean     2959.365926     155.656988      14.103723     269.428236   \n",
       "std       279.984569     111.913733       7.488234     212.549538   \n",
       "min      1859.000000       0.000000       0.000000       0.000000   \n",
       "25%      2809.000000      58.000000       9.000000     108.000000   \n",
       "50%      2996.000000     127.000000      13.000000     218.000000   \n",
       "75%      3163.000000     260.000000      18.000000     384.000000   \n",
       "max      3858.000000     360.000000      66.000000    1397.000000   \n",
       "\n",
       "                   0            510            221            232  \\\n",
       "count  581011.000000  581011.000000  581011.000000  581011.000000   \n",
       "mean       46.418935    2350.149779     212.146033     223.318701   \n",
       "std        58.295250    1559.254343      26.769909      19.768711   \n",
       "min      -173.000000       0.000000       0.000000       0.000000   \n",
       "25%         7.000000    1106.000000     198.000000     213.000000   \n",
       "50%        30.000000    1997.000000     218.000000     226.000000   \n",
       "75%        69.000000    3328.000000     231.000000     237.000000   \n",
       "max       601.000000    7117.000000     254.000000     254.000000   \n",
       "\n",
       "                 148           6279      ...                 0.34  \\\n",
       "count  581011.000000  581011.000000      ...        581011.000000   \n",
       "mean      142.528253    1980.283828      ...             0.090392   \n",
       "std        38.274561    1324.184340      ...             0.286743   \n",
       "min         0.000000       0.000000      ...             0.000000   \n",
       "25%       119.000000    1024.000000      ...             0.000000   \n",
       "50%       143.000000    1710.000000      ...             0.000000   \n",
       "75%       168.000000    2550.000000      ...             0.000000   \n",
       "max       254.000000    7173.000000      ...             1.000000   \n",
       "\n",
       "                0.35           0.36           0.37           0.38  \\\n",
       "count  581011.000000  581011.000000  581011.000000  581011.000000   \n",
       "mean        0.077716       0.002773       0.003255       0.000205   \n",
       "std         0.267725       0.052584       0.056957       0.014310   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "                0.39           0.40           0.41           0.42  \\\n",
       "count  581011.000000  581011.000000  581011.000000  581011.000000   \n",
       "mean        0.000513       0.026803       0.023762       0.015060   \n",
       "std         0.022641       0.161508       0.152307       0.121792   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "                   5  \n",
       "count  581011.000000  \n",
       "mean        2.051465  \n",
       "std         1.396500  \n",
       "min         1.000000  \n",
       "25%         1.000000  \n",
       "50%         2.000000  \n",
       "75%         2.000000  \n",
       "max         7.000000  \n",
       "\n",
       "[8 rows x 55 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(df):\n",
    "    columns = df.shape[1]\n",
    "    X = df[df.columns[0:columns - 1]]\n",
    "    X = (X[X.columns[0:10]] - X[X.columns[0:10]].mean())/X[X.columns[0:10]].std()\n",
    "    Y = pd.get_dummies(df[df.columns[columns - 1]])\n",
    "    return X.values, Y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(data, test_size=0.2, random_state=100)\n",
    "train_X, train_Y = create_dataset(train_set)\n",
    "test_X, test_Y = create_dataset(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_model(train_X, train_Y, test_X, test_Y):\n",
    "    weights = None\n",
    "    bias = None\n",
    "    X = tf.placeholder(tf.float32, shape=train_X.shape)\n",
    "    Y = tf.placeholder(tf.float32, shape=train_Y.shape)\n",
    "\n",
    "    w = tf.Variable(0.01*tf.random_normal(shape=(train_X.shape[1],1)))\n",
    "    b = tf.Variable(tf.zeros(train_Y.shape[1], 1))\n",
    "\n",
    "    Y_predicted = tf.nn.softmax(tf.matmul(X, w) + b) \n",
    "    \n",
    "    loss = -1000.0*tf.reduce_mean(Y*tf.log(Y_predicted))\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.005).minimize(loss)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        loss_values = []\n",
    "        epochs = 50\n",
    "        for i in range(epochs):\n",
    "            loss_val,_ = sess.run([loss, optimizer], feed_dict={X: train_X, Y: train_Y})\n",
    "            loss_values.append(loss_val)\n",
    "        \n",
    "        plt.plot(range(0, epochs), loss_values, '-')\n",
    "        plt.xlabel('Iterations')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.show()\n",
    "\n",
    "        weights, bias = sess.run([w, b])\n",
    "        \n",
    "        # Test the regression model\n",
    "        z = tf.matmul(tf.cast(test_X, tf.float32), weights) + bias\n",
    "        Y_test_predicted = tf.nn.softmax(z)\n",
    "        \n",
    "        correct_predictions = tf.equal(tf.argmax(Y_test_predicted, 1), tf.argmax(test_Y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
    "        return sess.run(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAkJERDJSQIiISEb/HyQETi0MmFF9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f69ef6ea6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.485504\n"
     ]
    }
   ],
   "source": [
    "accuracy = classification_model(train_X, train_Y, test_X, test_Y)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
