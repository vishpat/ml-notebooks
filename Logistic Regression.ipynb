{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Income prediction using Logistic Regression\n",
    "\n",
    "The data for this prediction model was obtained from [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names). The model trys to predict the income level of individuals using the census data. Since there are just two income levels, the model using Logistic regression with sigmoid activation function \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map all of the text labels in the data to integer values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(URL):\n",
    "    headers = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \n",
    "               \"education-num\", \"marital-status\", \"occupation\", \n",
    "               \"relationship\", \"race\", \"gender\", \"capital-gain\", \n",
    "               \"capital-loss\", \"hours-per-week\", \n",
    "               \"native-country\", \"income\"]\n",
    "    df = pd.read_csv(URL, header=None, names=headers)\n",
    "    df.head()\n",
    "    \n",
    "    # Map string labels to integers\n",
    "    for col in ['workclass', 'education', 'marital-status', \n",
    "                'occupation', 'relationship','race', 'gender', \n",
    "                'native-country', 'income']:\n",
    "        df[col] = df[col].astype('category')\n",
    "        df[col] = df[col].cat.codes\n",
    "        \n",
    "    df = (df-df.min())/(df.max()-df.min())\n",
    "    \n",
    "    X = df[[\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \n",
    "            \"marital-status\", \"occupation\", \"relationship\", \n",
    "            \"race\", \"gender\", \"capital-gain\", \"capital-loss\", \n",
    "            \"hours-per-week\", \"native-country\"]]\n",
    "    Y = df[[\"income\"]]\n",
    "    \n",
    "    return df,X.values,Y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.301370</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.044302</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.02174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.452055</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.048238</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.287671</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.138113</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.493151</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.151068</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.221488</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.121951</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  workclass    fnlwgt  education  education-num  marital-status  \\\n",
       "0  0.301370      0.875  0.044302   0.600000       0.800000        0.666667   \n",
       "1  0.452055      0.750  0.048238   0.600000       0.800000        0.333333   \n",
       "2  0.287671      0.500  0.138113   0.733333       0.533333        0.000000   \n",
       "3  0.493151      0.500  0.151068   0.066667       0.400000        0.333333   \n",
       "4  0.150685      0.500  0.221488   0.600000       0.800000        0.333333   \n",
       "\n",
       "   occupation  relationship  race  gender  capital-gain  capital-loss  \\\n",
       "0    0.071429           0.2   1.0     1.0       0.02174           0.0   \n",
       "1    0.285714           0.0   1.0     1.0       0.00000           0.0   \n",
       "2    0.428571           0.2   1.0     1.0       0.00000           0.0   \n",
       "3    0.428571           0.0   0.5     1.0       0.00000           0.0   \n",
       "4    0.714286           1.0   0.5     0.0       0.00000           0.0   \n",
       "\n",
       "   hours-per-week  native-country  income  \n",
       "0        0.397959        0.951220     0.0  \n",
       "1        0.122449        0.951220     0.0  \n",
       "2        0.397959        0.951220     0.0  \n",
       "3        0.397959        0.951220     0.0  \n",
       "4        0.397959        0.121951     0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data into a DataFrame\n",
    "train_df, train_X, train_Y = create_dataset('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data')\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.295639</td>\n",
       "      <td>0.483612</td>\n",
       "      <td>0.120545</td>\n",
       "      <td>0.686547</td>\n",
       "      <td>0.605379</td>\n",
       "      <td>0.435306</td>\n",
       "      <td>0.469481</td>\n",
       "      <td>0.289272</td>\n",
       "      <td>0.916464</td>\n",
       "      <td>0.669205</td>\n",
       "      <td>0.010777</td>\n",
       "      <td>0.020042</td>\n",
       "      <td>0.402423</td>\n",
       "      <td>0.895582</td>\n",
       "      <td>0.240810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.186855</td>\n",
       "      <td>0.181995</td>\n",
       "      <td>0.071685</td>\n",
       "      <td>0.258018</td>\n",
       "      <td>0.171515</td>\n",
       "      <td>0.251037</td>\n",
       "      <td>0.302061</td>\n",
       "      <td>0.321354</td>\n",
       "      <td>0.212201</td>\n",
       "      <td>0.470506</td>\n",
       "      <td>0.073854</td>\n",
       "      <td>0.092507</td>\n",
       "      <td>0.125994</td>\n",
       "      <td>0.190824</td>\n",
       "      <td>0.427581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.071679</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.273973</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.112788</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.424658</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.152651</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.448980</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age     workclass        fnlwgt     education  education-num  \\\n",
       "count  32561.000000  32561.000000  32561.000000  32561.000000   32561.000000   \n",
       "mean       0.295639      0.483612      0.120545      0.686547       0.605379   \n",
       "std        0.186855      0.181995      0.071685      0.258018       0.171515   \n",
       "min        0.000000      0.000000      0.000000      0.000000       0.000000   \n",
       "25%        0.150685      0.500000      0.071679      0.600000       0.533333   \n",
       "50%        0.273973      0.500000      0.112788      0.733333       0.600000   \n",
       "75%        0.424658      0.500000      0.152651      0.800000       0.733333   \n",
       "max        1.000000      1.000000      1.000000      1.000000       1.000000   \n",
       "\n",
       "       marital-status    occupation  relationship          race        gender  \\\n",
       "count    32561.000000  32561.000000  32561.000000  32561.000000  32561.000000   \n",
       "mean         0.435306      0.469481      0.289272      0.916464      0.669205   \n",
       "std          0.251037      0.302061      0.321354      0.212201      0.470506   \n",
       "min          0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%          0.333333      0.214286      0.000000      1.000000      0.000000   \n",
       "50%          0.333333      0.500000      0.200000      1.000000      1.000000   \n",
       "75%          0.666667      0.714286      0.600000      1.000000      1.000000   \n",
       "max          1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week  native-country  \\\n",
       "count  32561.000000  32561.000000    32561.000000    32561.000000   \n",
       "mean       0.010777      0.020042        0.402423        0.895582   \n",
       "std        0.073854      0.092507        0.125994        0.190824   \n",
       "min        0.000000      0.000000        0.000000        0.000000   \n",
       "25%        0.000000      0.000000        0.397959        0.951220   \n",
       "50%        0.000000      0.000000        0.397959        0.951220   \n",
       "75%        0.000000      0.000000        0.448980        0.951220   \n",
       "max        1.000000      1.000000        1.000000        1.000000   \n",
       "\n",
       "             income  \n",
       "count  32561.000000  \n",
       "mean       0.240810  \n",
       "std        0.427581  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.109589</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.144430</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.287671</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.051677</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.219011</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.369863</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.099418</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.076881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.060942</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.295918</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  workclass    fnlwgt  education  education-num  marital-status  \\\n",
       "0  0.109589       0.50  0.144430   0.066667       0.400000        0.666667   \n",
       "1  0.287671       0.50  0.051677   0.733333       0.533333        0.333333   \n",
       "2  0.150685       0.25  0.219011   0.466667       0.733333        0.333333   \n",
       "3  0.369863       0.50  0.099418   1.000000       0.600000        0.333333   \n",
       "4  0.013699       0.00  0.060942   1.000000       0.600000        0.666667   \n",
       "\n",
       "   occupation  relationship  race  gender  capital-gain  capital-loss  \\\n",
       "0    0.500000           0.6   0.5     1.0      0.000000           0.0   \n",
       "1    0.357143           0.0   1.0     1.0      0.000000           0.0   \n",
       "2    0.785714           0.0   1.0     1.0      0.000000           0.0   \n",
       "3    0.500000           0.0   0.5     1.0      0.076881           0.0   \n",
       "4    0.000000           0.6   1.0     0.0      0.000000           0.0   \n",
       "\n",
       "   hours-per-week  native-country  income  \n",
       "0        0.397959            0.95     0.0  \n",
       "1        0.500000            0.95     0.0  \n",
       "2        0.397959            0.95     1.0  \n",
       "3        0.397959            0.95     1.0  \n",
       "4        0.295918            0.95     0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df, test_X, test_Y = create_dataset('~/Downloads/adult.test')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_batch(X, Y, idx, batch_size):\n",
    "    return X[idx*batch_size: (idx + 1)*batch_size], Y[idx*batch_size: (idx + 1)*batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_model(train_X, train_Y, test_X, test_Y, epochs=10, regularization=0.1, batch_size=10):\n",
    "    weights = None\n",
    "    bias = None\n",
    "    regularization = 0.1\n",
    "    feature_cnt = train_X.shape[1]\n",
    "    \n",
    "    # Mini Batch Gradient descent parameters\n",
    "    batch_cnt = int(train_X.shape[0]/batch_size)\n",
    "    \n",
    "    X = tf.placeholder(tf.float32, shape=(None, feature_cnt), name='X')\n",
    "    Y = tf.placeholder(tf.float32, shape=(None, 1), name='Y')\n",
    "\n",
    "    w = tf.Variable(tf.random_normal(shape=(feature_cnt, 1)), name='W')\n",
    "    b = tf.Variable(0.0, name='b')\n",
    "\n",
    "    Y_predicted = tf.nn.sigmoid(tf.matmul(X, w) + b) \n",
    "    \n",
    "    loss = tf.reduce_mean(-(Y*tf.log(Y_predicted) + (1 - Y)*tf.log(1 - Y_predicted)) \n",
    "                          + regularization*tf.reduce_sum(tf.square(w)))\n",
    "    \n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(loss)\n",
    "    \n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "  \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        loss_values = []\n",
    "        for i in range(epochs):\n",
    "            for idx in range(0, batch_cnt):\n",
    "                mini_X, mini_Y = get_next_batch(train_X, train_Y, idx, batch_size)\n",
    "            \n",
    "                train_loss_val,_ = sess.run([loss, optimizer], feed_dict={X: mini_X, Y: mini_Y})\n",
    "                train_losses.append(train_loss_val)\n",
    "                \n",
    "                test_loss_val = sess.run([loss], feed_dict={X: test_X, Y: test_Y})\n",
    "                test_losses.append(test_loss_val)\n",
    "    \n",
    "                \n",
    "        plt.plot(range(0, epochs*batch_cnt), train_losses, '-',label='training')\n",
    "        plt.plot(range(0, epochs*batch_cnt), test_losses, '-', label='test')\n",
    "        plt.xlabel('Iterations')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()  \n",
    "       \n",
    "        # Test the regression model\n",
    "        y_test_predictions = sess.run(Y_predicted,)   \n",
    "        logit = lambda x: 1.0 if x > 0.5 else 0.0\n",
    "        vfunc = np.vectorize(logit)\n",
    "        y_test_predictions = vfunc(y_test_predictions)\n",
    "        return np.sum(y_test_predictions == test_Y)/test_Y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcd4e5469e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "None values not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-198c46f19d7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic_regression_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-1a1ae0693c90>\u001b[0m in \u001b[0;36mlogistic_regression_model\u001b[0;34m(train_X, train_Y, test_X, test_Y, epochs, regularization, batch_size)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# Test the regression model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mY_test_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0my_test_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test_predicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   1797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1798\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"a\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1799\u001b[0;31m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1800\u001b[0m     \u001b[0ma_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1801\u001b[0m     \u001b[0mb_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m           \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    119\u001b[0m                                          as_ref=False):\n\u001b[1;32m    120\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0mtensor_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[0;32m--> 102\u001b[0;31m       tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    103\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    362\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"None values not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m     \u001b[0;31m# if dtype is provided, forces numpy array to be the type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;31m# provided if possible.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: None values not supported."
     ]
    }
   ],
   "source": [
    "accuracy = logistic_regression_model(train_X, train_Y, test_X, test_Y, batch_size=1000)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
